{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec45ca4-14f8-4eea-9e4a-f64e0bca9e10",
   "metadata": {},
   "source": [
    "# Part I) Data Scraping\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ad86d5-7895-4dc2-b73e-0cf556450a85",
   "metadata": {},
   "source": [
    "### 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d6f94a0-e131-42f9-8b07-98dece579ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a1258-aaae-4906-ae19-9fa091cc6a13",
   "metadata": {},
   "source": [
    "---\n",
    "### 2) Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "27637851-d950-4b45-91d3-bad35ee8ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_html(link, tag, sleep=7, retries=3):\n",
    "    '''\n",
    "        Retrieve HTMl for given link; used for get_season() function\n",
    "        Includes sleep parameter to make sure scraping doesn't occur too fast; or else\n",
    "        you can blocked from the website. Results in slower, but continuous, scraping\n",
    "        \n",
    "        link = url\n",
    "        tag = specific id tag to retrieve\n",
    "        sleep = number of seconds to wait\n",
    "        \n",
    "        This function will \n",
    "    '''\n",
    "    html = None\n",
    "    for i in range(1, retries+1):\n",
    "        time.sleep(sleep * i) # Don't scrape too fast because you can get banned; pauses program for a  seconds\n",
    "        try:\n",
    "            async with async_playwright() as p:\n",
    "                browser = await p.webkit.launch()\n",
    "                page = await browser.new_page()\n",
    "                await page.goto(link)\n",
    "                print(await page.title())\n",
    "                html = await page.inner_html(tag)\n",
    "        except PlaywrightTimeout:\n",
    "            print(f\"Timeout error on {link}\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return html\n",
    "\n",
    "async def get_season(season, directory):\n",
    "    '''\n",
    "        Scrape entire html for all NBA games for each month of each season\n",
    "    '''\n",
    "    link = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "    html = await get_html(link, \"#content .filter\")\n",
    "    \n",
    "    soup = BeautifulSoup(html)\n",
    "    links = soup.find_all(\"a\")\n",
    "    standings_pages = [f\"https://www.basketball-reference.com{l['href']}\" for l in links]\n",
    "    \n",
    "    for link in standings_pages:\n",
    "        save_path = os.path.join(directory, url.split(\"/\")[-1])\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "        \n",
    "        html = await get_html(link, \"#all_schedule\") #\n",
    "        with open(save_path, \"w+\") as f:\n",
    "            f.write(html)\n",
    "            \n",
    "async def scrape_box_score_data(all_games, directory):\n",
    "    '''\n",
    "    3) Parse Box Score links for all games in a given month\n",
    "    \n",
    "    all_games = html file \n",
    "    \n",
    "    '''\n",
    "    with open(all_games, 'r') as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    all_links = soup.find_all(\"a\")\n",
    "    all_hrefs = [l.get('href') for l in all_links] # Just grab href portion of anchor tag\n",
    "    all_box_scores = [f\"https://www.basketball-reference.com{l}\" for l in all_hrefs \n",
    "                  if l and \"boxscore\" in l and '.html' in l] # Filter hrefs to just box scores\n",
    "\n",
    "    for game in box_scores: #Loop through each box score\n",
    "        path = os.path.join(directory, game.split(\"/\")[-1]) # Filename will be end of url (ID of box score)\n",
    "        if os.path.exists(path): # Keep running loop and ignore files that are already scraped\n",
    "            continue\n",
    "\n",
    "        html = await get_html(game, \"#content\") # Only grab html for id='content', which contains all the statistics to scrape\n",
    "        if not html: # If html is tried to be downloaded 3 or more times (based on get_html function) and its failed, then continue to loop\n",
    "            continue\n",
    "        with open(path, \"w+\") as f:\n",
    "            f.write(html)\n",
    "            \n",
    "async def execute_scrape(season, seasons_dir, scores_dir):\n",
    "    await get_season(season, seasons_dir) #Scrape the seasons game schedules\n",
    "    all_games = os.listdir(seasons_dir) # take all html's (for each month of games) for given season\n",
    "    all_games.remove('.ipynb_checkpoints')\n",
    "\n",
    "    for month in all_games: \n",
    "        path = os.path.join(seasons_dir, month)\n",
    "        await scrape_box_score_data(path, scores_dir) # Scrape box score data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1ac37d-d635-4726-8406-5b17566921af",
   "metadata": {},
   "source": [
    "---\n",
    "### 3) Scrape 2023 NBA Box Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f6f6e4f-ec34-4f12-b050-44c594935c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_data = \"../data\"\n",
    "directory_schedules = os.path.join(directory_data, \"standings\") # information that lists all boxscores out\n",
    "directory_box_scores = os.path.join(directory_data, \"scores\") # Box scores\n",
    "\n",
    "season = 2023\n",
    "# Note: already scraped 2023 in an older notebook; takes a long time to scrape, which is why\n",
    "# the execute_scrape is commented out\n",
    "#await execute_scrape(season, directory_schedules, directory_box_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4884119c-8a47-42a7-8dfb-98511e73cef2",
   "metadata": {},
   "source": [
    "---\n",
    "### 4) Functions to Parse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a86ee5-0072-4acd-9947-338a1b86b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(score):\n",
    "    '''\n",
    "        Clean up html of box scores by removing unnecessary headers or lines in the middle of the box score\n",
    "        we eventually want to parse through.\n",
    "    '''\n",
    "    with open(score) as f:\n",
    "        html = f.read()\n",
    "    soup = BeautifulSoup(html) # Create instance of BeautifulSoup to parse html\n",
    "    # Use list comprehension to remove unnecessary headers with soup's decompose function\n",
    "    [s.decompose() for s in soup.select('tr.over_header')] # Remove headers of box score (such as 'Basic Box Score Stats');\n",
    "    [s.decompose() for s in soup.select('tr.thead')] # Remove \"Reserves\" heaader in the middle of the box score\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5229586-03a4-4457-b730-8465f44c9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_game_score(soup):\n",
    "    '''\n",
    "        Return two columns that contain the two teams and their respective points scored for a given game\n",
    "        How: parsing the \"Line Score\" table within html ('id' = 'line_score')\n",
    "        \n",
    "        Note: Line box score contains the quarter-by-quarter breakdown of how many points each team scored;\n",
    "        just want the total points\n",
    "    '''\n",
    "    line_box_score = pd.read_html(str(soup), attrs = {'id':'line_score'})[0] # use pandas read_html function\n",
    "    \n",
    "    new_vars = list(line_box_score.columns) # Change column names\n",
    "    new_vars[0] = 'team'\n",
    "    new_vars[-1] = 'total'\n",
    "    line_box_score.columns = new_vars\n",
    "    \n",
    "    return line_box_score[['team','total']] # Remove quarter scores and just keep team and total points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e435920-dbdb-4924-95b0-582aef4c5a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_stats(soup,\n",
    "                    team,\n",
    "                    stat_type\n",
    "                   ):\n",
    "    '''\n",
    "        Return dataframe that parses through a given table of statistics from the Box Score html\n",
    "        \n",
    "        soup = Instance of BeautifulSoup to parse html\n",
    "        team = Specify which team to parse stats for; 3 letters all caps (ex: 'DET' = Detroit Pistons)\n",
    "        stat_type = Argument for type of statistics we're trying to parse; only parsing \"Basic\" or \"Advanced\"\n",
    "    '''\n",
    "    stats_df = pd.read_html(str(soup), attrs = {'id':f\"box-{team}-game-{stat_type}\"}, \n",
    "                            index_col=0)[0] # Index at 0 gives list by default; index_col: first column should be an index,\n",
    "    stats_df = stats_df.apply(pd.to_numeric, errors='coerce') # Change columns to numeric       \n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "826d8130-0fa0-4305-a2f1-325a48892ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_season_date(soup):\n",
    "    '''\n",
    "    Return the season for which the box score html is recorded from.\n",
    "    \n",
    "    How: Selecting\n",
    "    '''\n",
    "    nav = soup.select('#bottom_nav_container')[0] # Season date is within this container\n",
    "    hrefs = [a['href'] for a in nav.find_all('a')] # Grab all anchor tags, then grab links in bottom nav container\n",
    "    season_date = os.path.basename(hrefs[1]).split('_')[0] # Grab link for date; index for portion with date, split on underscore, and grab just the date\n",
    "    return season_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "867d3702-7b84-4705-99d1-9a26369e54ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test with one box score\n",
    "\n",
    "one_score = all_box_scores[0]\n",
    "soup = clean_html(box_score)\n",
    "line_box_score = parse_game_score(soup)\n",
    "teams = list(line_box_score['team'])\n",
    "\n",
    "summaries = [] \n",
    "for team in teams:\n",
    "    basic_stats = parse_all_stats(soup, team, 'basic')\n",
    "    advanced_stats = parse_all_stats(soup, team, 'advanced')\n",
    "    basic_totals = basic_stats.iloc[-1,:]\n",
    "    advanced_totals = advanced_stats.iloc[-1,:]\n",
    "    all_totals = pd.concat([basic_totals,advanced_totals])\n",
    "    all_totals.index = all_totals.index.str.lower()\n",
    "    \n",
    "    if set_cols is None:\n",
    "        set_cols = list(all_totals.index.drop_duplicates(keep='first')) \n",
    "        set_cols = [col for col in set_cols if 'bpm' not in col] \n",
    "\n",
    "    all_totals = all_totals[set_cols]\n",
    "    summaries.append(all_totals)\n",
    "\n",
    "\n",
    "summary = pd.concat(summaries, axis=1).T.reset_index(drop=True)\n",
    "summary = pd.concat([summary,line_box_score],axis=1)\n",
    "summary['home'] = [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ee1bb2-852e-4320-95d6-7ffbfcdde83e",
   "metadata": {},
   "source": [
    "---\n",
    "### 5) Parse 2023 NBA Data and Export to CSV for Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "36453579-7b2d-47a5-827a-cdce9f29c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_box_scores = os.listdir(directory_box_scores)\n",
    "all_box_scores = [os.path.join(directory_box_scores,game) for game in all_box_scores if game.endswith('.html')] # Make sure it's just html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53ac66e5-2191-4bac-8e3b-0e10d27b041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games = [] # List that will contain all stats for each single game\n",
    "set_cols = None # \n",
    "\n",
    "for box_score in all_box_scores:\n",
    "    soup = clean_html(box_score)\n",
    "    line_box_score = parse_game_score(soup)\n",
    "    teams = list(line_box_score['team']) # Get Team names\n",
    "    \n",
    "    summaries = [] # List that contains the box score data for both teams in a game\n",
    "    for team in teams:\n",
    "        basic_stats = parse_all_stats(soup, team, 'basic')\n",
    "        advanced_stats = parse_all_stats(soup, team, 'advanced') # Get basic and advanced stats for each team\n",
    "        \n",
    "        basic_totals = basic_stats.iloc[-1,:] # Only grab the totals for each statistic by grabbing last row of df\n",
    "        advanced_totals = advanced_stats.iloc[-1,:]\n",
    "        \n",
    "        all_totals = pd.concat([basic_totals,advanced_totals]) # Concatenate totals for both basic and advanced stats\n",
    "        all_totals.index = all_totals.index.str.lower() # Convert all variable names to lowercase\n",
    "        \n",
    "        if set_cols is None: # If there are no set cols, create standardized set of columns\n",
    "            set_cols = list(all_totals.index.drop_duplicates(keep='first')) # Drop duplicate columns\n",
    "            set_cols = [col for col in set_cols if 'bpm' not in col] # bpm exists in some box scores but not in others, so just remove it\n",
    "        \n",
    "        all_totals = all_totals[set_cols]\n",
    "        \n",
    "        summaries.append(all_totals) # append to summaries list \n",
    "    \n",
    "    game_summary = pd.concat(summaries, axis=1).T.reset_index(drop=True) # Combine stats for the two teams in a game into one dataframe\n",
    "    game_summary = pd.concat([game_summary,line_box_score],axis=1) # Concatenate name of team and total points\n",
    "    \n",
    "    game_summary['home'] = [0,1] # The way game_summary is set up, the first row is away team (0), and second row is home (1)\n",
    "    \n",
    "    # We want each row to contain stats for opposing team, so we first need to create dataframe that reverses order of game_summmary\n",
    "    opponent_summary = game_summary.iloc[::-1].reset_index() # Reverse rows of game_summary dataframe\n",
    "    opponent_summary.columns = opponent_summary.columns + '_opp' # Distinguish column names\n",
    "    \n",
    "    entire_game_summary = pd.concat([game_summary, opponent_summary],axis=1) # Combine so information about team and its opponent are on same row\n",
    "    \n",
    "    entire_game_summary['season'] = parse_season_date(soup) # Add season to dataframe\n",
    "    entire_game_summary['date'] = os.path.basename(box_score)[:8] # Date is contained in path to box score html file; first 8 characters give year, month and date\n",
    "    entire_game_summary['date'] = pd.to_datetime(entire_game_summary['date'],format='%Y%m%d') # Convert to datetime type\n",
    "    \n",
    "    # Need to determine who won: compare if team's total is greater than opponent's total\n",
    "    entire_game_summary['won'] = entire_game_summary['total'] > entire_game_summary['total_opp'] \n",
    "    all_games.append(entire_game_summary)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d15893b3-bcf4-46b0-976c-d5f1ee9e0059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mp</th>\n",
       "      <th>mp</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg%</th>\n",
       "      <th>3p</th>\n",
       "      <th>3pa</th>\n",
       "      <th>3p%</th>\n",
       "      <th>ft</th>\n",
       "      <th>fta</th>\n",
       "      <th>...</th>\n",
       "      <th>tov%_opp</th>\n",
       "      <th>usg%_opp</th>\n",
       "      <th>ortg_opp</th>\n",
       "      <th>drtg_opp</th>\n",
       "      <th>team_opp</th>\n",
       "      <th>total_opp</th>\n",
       "      <th>home_opp</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.528</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.432</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>114.1</td>\n",
       "      <td>117.3</td>\n",
       "      <td>MIA</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.476</td>\n",
       "      <td>14.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.359</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>117.3</td>\n",
       "      <td>114.1</td>\n",
       "      <td>POR</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.526</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.7</td>\n",
       "      <td>119.8</td>\n",
       "      <td>DAL</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>119.8</td>\n",
       "      <td>102.7</td>\n",
       "      <td>CLE</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.425</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.212</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>119.4</td>\n",
       "      <td>107.1</td>\n",
       "      <td>TOR</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>265.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>14.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.2</td>\n",
       "      <td>104.6</td>\n",
       "      <td>GSW</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.360</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.209</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>90.2</td>\n",
       "      <td>GSW</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.419</td>\n",
       "      <td>14.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.304</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.2</td>\n",
       "      <td>114.0</td>\n",
       "      <td>LAC</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.576</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.444</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.8</td>\n",
       "      <td>127.8</td>\n",
       "      <td>SAC</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.528</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.452</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>127.8</td>\n",
       "      <td>128.8</td>\n",
       "      <td>DEN</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mp     mp    fg    fga    fg%    3p   3pa    3p%    ft   fta  ...  \\\n",
       "0     240.0  240.0  38.0   72.0  0.528  16.0  37.0  0.432  18.0  21.0  ...   \n",
       "1     240.0  240.0  40.0   84.0  0.476  14.0  39.0  0.359  13.0  15.0  ...   \n",
       "2     240.0  240.0  41.0   78.0  0.526   8.0  24.0  0.333  15.0  19.0  ...   \n",
       "3     240.0  240.0  29.0   74.0  0.392  13.0  38.0  0.342  19.0  26.0  ...   \n",
       "4     240.0  240.0  37.0   87.0  0.425   7.0  33.0  0.212  32.0  35.0  ...   \n",
       "...     ...    ...   ...    ...    ...   ...   ...    ...   ...   ...  ...   \n",
       "2635  265.0  265.0  46.0  106.0  0.434  14.0  50.0  0.280  13.0  24.0  ...   \n",
       "2636  240.0  240.0  32.0   89.0  0.360   9.0  43.0  0.209  18.0  21.0  ...   \n",
       "2637  240.0  240.0  39.0   93.0  0.419  14.0  46.0  0.304  23.0  27.0  ...   \n",
       "2638  240.0  240.0  49.0   85.0  0.576  12.0  27.0  0.444  16.0  18.0  ...   \n",
       "2639  240.0  240.0  47.0   89.0  0.528  14.0  31.0  0.452  19.0  25.0  ...   \n",
       "\n",
       "      tov%_opp  usg%_opp  ortg_opp  drtg_opp  team_opp  total_opp  home_opp  \\\n",
       "0          9.9     100.0     114.1     117.3       MIA        107         1   \n",
       "1         18.1     100.0     117.3     114.1       POR        110         0   \n",
       "2         12.3     100.0     102.7     119.8       DAL         90         1   \n",
       "3          6.5     100.0     119.8     102.7       CLE        105         0   \n",
       "4          8.6     100.0     119.4     107.1       TOR        126         1   \n",
       "...        ...       ...       ...       ...       ...        ...       ...   \n",
       "2635      13.8     100.0     100.2     104.6       GSW        114         0   \n",
       "2636       9.5     100.0     114.0      90.2       GSW        115         1   \n",
       "2637      14.0     100.0      90.2     114.0       LAC         91         0   \n",
       "2638      10.7     100.0     128.8     127.8       SAC        127         1   \n",
       "2639      14.7     100.0     127.8     128.8       DEN        126         0   \n",
       "\n",
       "      season       date    won  \n",
       "0       2023 2022-11-07   True  \n",
       "1       2023 2022-11-07  False  \n",
       "2       2023 2022-12-14   True  \n",
       "3       2023 2022-12-14  False  \n",
       "4       2023 2022-12-07  False  \n",
       "...      ...        ...    ...  \n",
       "2635    2023 2023-02-01   True  \n",
       "2636    2023 2023-03-02  False  \n",
       "2637    2023 2023-03-02   True  \n",
       "2638    2023 2022-12-28  False  \n",
       "2639    2023 2022-12-28   True  \n",
       "\n",
       "[2640 rows x 80 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data_2023 = pd.concat(all_games,ignore_index=True) # Concatenate all the gamesinto one dataframe; treat games as rows\n",
    "nba_data_2023.to_csv('../data/nba_games_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9d1db-f0ca-4f2d-953e-3906191f170b",
   "metadata": {},
   "source": [
    "---\n",
    "### 6) 2023-2024 NBA Season Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c55643-50c9-4633-99c8-0c3cf7d5fdb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
