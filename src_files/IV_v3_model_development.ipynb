{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62fca8fe-9175-4ce8-9210-55bcacb7a7a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part III: Model Development\n",
    "\n",
    "Key Points:\n",
    "1. Training dataset will be historical data from 2016-2021\n",
    "2. Test dataset (for now) will be data from 2022 season\n",
    "3. Models to Try:\n",
    "   - Logistic Regression\n",
    "   - K-Nearest Neighbors\n",
    "   - Naive Bayes Classifier\n",
    "   - LightGBM and XGBoost\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae476337-cdfc-48bc-ab4b-a46d9dd725fa",
   "metadata": {},
   "source": [
    "### 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644830b2-1841-47bb-a853-b04cf2c8bca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-4.1.0-py3-none-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from lightgbm) (1.24.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from lightgbm) (1.11.3)\n",
      "Using cached lightgbm-4.1.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77e4296-3804-4bcc-b5cc-a186c72b5897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.0.2-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from xgboost) (1.11.3)\n",
      "Using cached xgboost-2.0.2-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77da6572-c4b2-4ad4-9f19-c697886c24c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb5179be-9dae-4763-9a85-623d4893b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import III_feature_engineering as III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5974cd6f-3219-4fff-a361-6a7c00c3e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(III);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be9c0401-20c6-4839-8c1c-2ac9dc95e512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,roc_curve\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43acc6e6-5300-4173-8cd2-ca31e0e0868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d889fd6-4bab-49c8-81b9-fe9e37b76a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43bdf957-1b3b-4a9c-9461-71a3e99970a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Cleaned Data produced from Notebook II\n",
    "nba_clean_data = pd.read_csv('../data/cleaned_nba_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a881a4-d76d-43da-a34d-01d80f0a54bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "### 2) Create Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0dfd8f33-6d50-470a-989a-d34e745def24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_test_split(data,\n",
    "                     model_vars,\n",
    "                     year,\n",
    "                     num_games_list,\n",
    "                     remove_placeholder_target = False,\n",
    "                     compute_avg = False,\n",
    "                     compute_rolling_avg = False,\n",
    "                     drop_na_rows=False\n",
    "                    ):\n",
    "    '''\n",
    "    Return the training and testing features and targets for the given nba dataset:\n",
    "\n",
    "    original_data = DataFrame with all NBA Box Score data from 2016-2022\n",
    "    transformed_data = DataFrame with transformed features, such as rolling averages, W/L streaks\n",
    "\n",
    "    '''\n",
    "    if remove_placeholder_target:\n",
    "        target_indices_drop = data[data['target'] == -1].index # Remove rows where target = -1 (i.e. last game of the season), so no outcome\n",
    "        new_data = data.drop(target_indices_drop)\n",
    "    \n",
    "    \n",
    "    # Subset training and testing data by year\n",
    "    new_data = new_data.sort_values(['team','season','date']).reset_index(drop=True)\n",
    "    new_data = new_data.sort_values(['season','date']).reset_index(drop=True) # Weird sorting to make sure train and test targets match up\n",
    "\n",
    "    nba_train = new_data[new_data['season'] != year].reset_index(drop=True)\n",
    "    nba_test = new_data[new_data['season'] == year].reset_index(drop=True)\n",
    "\n",
    "    train_target = nba_train['target'] # Subset the targets before potentially computing rolling_averages\n",
    "    test_target = nba_test['target']\n",
    "\n",
    "    if compute_avg:\n",
    "        train_data = III.create_averages(nba_train,\n",
    "                                         model_vars,\n",
    "                                         train_only=True,\n",
    "                                         include_target=False\n",
    "                                        )\n",
    "        test_data = III.create_averages(nba_test,\n",
    "                                        model_vars,\n",
    "                                        train_only=True,\n",
    "                                        include_target=False)\n",
    "    \n",
    "    elif compute_rolling_avg:\n",
    "        train_data = III.create_rolling_averages(nba_train,\n",
    "                                             model_vars,\n",
    "                                             num_games_list,\n",
    "                                             train_only=True\n",
    "                                            ) \n",
    "        test_data = III.create_rolling_averages(nba_test,\n",
    "                                           model_vars,\n",
    "                                           num_games_list,\n",
    "                                           train_only=True\n",
    "                                           )\n",
    "\n",
    "        if drop_na_rows: # For certain algorithms that don't recognize NaN values (i.e. first 5 rows of each team)\n",
    "            nan_train_idx = train_data.index[train_data.isna().any(axis=1)].to_list()\n",
    "            nan_test_idx = test_data.index[test_data.isna().any(axis=1)].to_list()\n",
    "            \n",
    "            train_data = train_data.drop(nan_train_idx).reset_index(drop=True)\n",
    "            test_data = test_data.drop(nan_test_idx).reset_index(drop=True)\n",
    "\n",
    "            # Need to drop the same row indices for target\n",
    "            train_target = train_target.drop(nan_train_idx).reset_index(drop=True)\n",
    "            test_target = test_target.drop(nan_test_idx).reset_index(drop=True)\n",
    "            \n",
    "    else:\n",
    "        train_data = nba_train[model_vars]\n",
    "        test_data = nba_test[model_vars]\n",
    "    \n",
    "    return train_data, train_target, test_data, test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14693ce-127f-4662-8f10-9a1b855a96c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2b) Establish Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b3f6af3-a9f7-4045-8e1e-c88cdcf208b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure functions work from other .py file\n",
    "model_variables = III.create_model_variables(nba_clean_data) # Establish model variables\n",
    "nba_transformed = III.create_rolling_averages(nba_clean_data, # Create new dataframe with two different rolling averages\n",
    "                                          model_variables,\n",
    "                                          num_games_list=[3,5],\n",
    "                                          train_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce36e9fc-3420-43ad-9996-5d64c4e8a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish training and testing sets\n",
    "model_variables = III.create_model_variables(nba_clean_data) # Establish model variables\n",
    "X_train, y_train, X_test, y_test = train_test_split(nba_clean_data,\n",
    "                                                    model_variables,\n",
    "                                                    2022,\n",
    "                                                    [3,5,10], \n",
    "                                                    True,True,True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77cc9c7-d12d-463f-b0b8-06bde29f29d6",
   "metadata": {},
   "source": [
    "### 3) Baseline Logistic Regression Model\n",
    "\n",
    "1) Trial 1: Baseline (max_iter = 5000)\n",
    "    - Parameters: 2 rolling averages (3 and 5 games)\n",
    "    - Train Accuracy = 0.53\n",
    "    - Test Accuracy = 0.52\n",
    "    - Precision (Class 1) = 0.51\n",
    "    - Recall (Class 1) = 0.61\n",
    "    - F1-Score = 0.56\n",
    "\n",
    "2) Trial 2: Only 5 game average:\n",
    "    - Train = 0.52\n",
    "    - Test = 0.49\n",
    "    - Precision = 0.49\n",
    "    - Recall = 0.64\n",
    "    - F1-Score = 0.55\n",
    "\n",
    "3) Trial 3: 3,5,10 game averages:\n",
    "    - Train = 0.54\n",
    "    - Test = 0.52\n",
    "    - Precision = 0.52\n",
    "    - Recall = 0.61\n",
    "    - F1-Score = 0.56\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f4ab30a-5fe3-4ec5-a48e-8e27094c2673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.534969233078193, 0.5191815856777494]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train baseline logistic Regression Model\n",
    "log_reg = LR(max_iter = 5000, random_state = 0) #baseline model\n",
    "ss = SS()\n",
    "\n",
    "train_s = ss.fit_transform(X_train) # Standardize of training and testing features\n",
    "test_s = ss.transform(X_test) \n",
    "\n",
    "log_reg.fit(train_s,y_train) # fit logistic regression\n",
    "\n",
    "[log_reg.score(train_s,y_train), log_reg.score(test_s,y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "100f4402-6220-4845-9314-b0d9844af378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.43      0.47      1175\n",
      "           1       0.52      0.61      0.56      1171\n",
      "\n",
      "    accuracy                           0.52      2346\n",
      "   macro avg       0.52      0.52      0.52      2346\n",
      "weighted avg       0.52      0.52      0.52      2346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred = log_reg.predict(train_s)\n",
    "test_pred = log_reg.predict(test_s)\n",
    "\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc74d8c-efee-4313-9333-281953f9e0cf",
   "metadata": {},
   "source": [
    "---\n",
    "### 4) Logistic Regression with Consecutive Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e413a2f-6b4a-4841-a231-0947d0def661",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variables = III.create_model_variables(nba_clean_data) # Establish model variables\n",
    "nba_transformed = III.create_averages(nba_clean_data,model_variables,train_only=True,include_target=False)\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(nba_clean_data,\n",
    "                                                    model_variables,\n",
    "                                                    2022,\n",
    "                                                    None, \n",
    "                                                    True,True,\n",
    "                                                    False,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fcca3992-504e-4d02-9d8e-9060792fd777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5102368526696106, 0.5107033639143731]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LR(max_iter = 5000, random_state = 0) #baseline model\n",
    "ss = SS()\n",
    "\n",
    "train_s = ss.fit_transform(X_train) # Standardize of training and testing features\n",
    "test_s = ss.transform(X_test) \n",
    "\n",
    "log_reg.fit(train_s,y_train) # fit logistic regression\n",
    "\n",
    "[log_reg.score(train_s,y_train), log_reg.score(test_s,y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d15ca65-a37e-44b8-9305-706a064f72f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.55      0.53      1308\n",
      "           1       0.51      0.47      0.49      1308\n",
      "\n",
      "    accuracy                           0.51      2616\n",
      "   macro avg       0.51      0.51      0.51      2616\n",
      "weighted avg       0.51      0.51      0.51      2616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred = log_reg.predict(train_s)\n",
    "test_pred = log_reg.predict(test_s)\n",
    "\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b824b123-bc08-48fd-8de7-5f4e9bd8d20b",
   "metadata": {},
   "source": [
    "---\n",
    "### 5) K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "53d0c0fe-81c3-4093-95db-28810837249a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.52      0.51      1308\n",
      "           1       0.50      0.48      0.49      1308\n",
      "\n",
      "    accuracy                           0.50      2616\n",
      "   macro avg       0.50      0.50      0.50      2616\n",
      "weighted avg       0.50      0.50      0.50      2616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_s = ss.fit_transform(X_train) # Standardize of training and testing features\n",
    "test_s = ss.transform(X_test) \n",
    "\n",
    "k = 13\n",
    "knn = KNN(n_neighbors=k)\n",
    "knn.fit(train_s,y_train) # fit logistic regression\n",
    "#print(knn.score(train_s,y_train),knn.score(test_s, y_test))\n",
    "\n",
    "test_pred = knn.predict(test_s)\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a16b2-d108-47e2-859c-60e9b0875b01",
   "metadata": {},
   "source": [
    "---\n",
    "### 6) LightGBM Classiifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4483020a-bde4-4ab2-88a3-bc6add780184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5501137428074401, 0.518348623853211]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.55      0.53      1308\n",
      "           1       0.52      0.49      0.50      1308\n",
      "\n",
      "    accuracy                           0.52      2616\n",
      "   macro avg       0.52      0.52      0.52      2616\n",
      "weighted avg       0.52      0.52      0.52      2616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_classifier = lgb.LGBMClassifier(num_leaves=10, max_depth=2,random_state=0,verbose=-1)\n",
    "\n",
    "lgb_classifier.fit(X_train,y_train)\n",
    "print([lgb_classifier.score(X_train,y_train),lgb_classifier.score(X_test,y_test)])\n",
    "test_pred = lgb_classifier.predict(X_test)\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9078b95-88bf-45c1-a351-14f9ab73ef2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "## Part II: Combine Features\n",
    "\n",
    "Note: Need to make more functions for train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c647a935-a81a-4ffc-a9cd-bebaed56cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variables = III.create_model_variables(nba_clean_data) # Establish model variables\n",
    "nba_transformed = III.create_averages(nba_clean_data,model_variables,train_only=True,include_target=False)\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(nba_clean_data,\n",
    "                                                    model_variables,\n",
    "                                                    2022,\n",
    "                                                    [3,5], \n",
    "                                                    True,False,\n",
    "                                                    True,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "84a7fdce-505c-44e0-87dd-f455f16fc2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fga_avg_L3</th>\n",
       "      <th>fg%_avg_L3</th>\n",
       "      <th>3pa_avg_L3</th>\n",
       "      <th>3p%_avg_L3</th>\n",
       "      <th>fta_avg_L3</th>\n",
       "      <th>ft%_avg_L3</th>\n",
       "      <th>orb_avg_L3</th>\n",
       "      <th>trb_avg_L3</th>\n",
       "      <th>ast_avg_L3</th>\n",
       "      <th>stl_avg_L3</th>\n",
       "      <th>...</th>\n",
       "      <th>tov_opp_avg_L5</th>\n",
       "      <th>pf_opp_avg_L5</th>\n",
       "      <th>pts_opp_avg_L5</th>\n",
       "      <th>ts%_opp_avg_L5</th>\n",
       "      <th>efg%_opp_avg_L5</th>\n",
       "      <th>3par_opp_avg_L5</th>\n",
       "      <th>drb%_opp_avg_L5</th>\n",
       "      <th>trb%_opp_avg_L5</th>\n",
       "      <th>ortg_opp_avg_L5</th>\n",
       "      <th>drtg_opp_avg_L5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.666667</td>\n",
       "      <td>0.463667</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>0.353667</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.666667</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>0.335333</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.421667</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>0.307333</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>16.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>79.74</td>\n",
       "      <td>53.34</td>\n",
       "      <td>100.26</td>\n",
       "      <td>102.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14941</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>0.809667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2</td>\n",
       "      <td>18.6</td>\n",
       "      <td>113.6</td>\n",
       "      <td>0.5522</td>\n",
       "      <td>0.5042</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>77.84</td>\n",
       "      <td>48.18</td>\n",
       "      <td>109.36</td>\n",
       "      <td>113.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14942</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.524333</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.347667</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>0.806333</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>12.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>114.6</td>\n",
       "      <td>0.5464</td>\n",
       "      <td>0.4998</td>\n",
       "      <td>0.4262</td>\n",
       "      <td>77.12</td>\n",
       "      <td>47.10</td>\n",
       "      <td>110.90</td>\n",
       "      <td>114.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14943</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.330333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>44.333333</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>11.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>117.6</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>0.3882</td>\n",
       "      <td>76.82</td>\n",
       "      <td>48.00</td>\n",
       "      <td>114.30</td>\n",
       "      <td>110.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14944</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.731000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>77.02</td>\n",
       "      <td>50.24</td>\n",
       "      <td>118.90</td>\n",
       "      <td>108.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14945</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.417667</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.231667</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>0.726333</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>12.4</td>\n",
       "      <td>22.6</td>\n",
       "      <td>121.2</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>0.5608</td>\n",
       "      <td>0.3536</td>\n",
       "      <td>77.14</td>\n",
       "      <td>49.38</td>\n",
       "      <td>116.98</td>\n",
       "      <td>111.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14946 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fga_avg_L3  fg%_avg_L3  3pa_avg_L3  3p%_avg_L3  fta_avg_L3  ft%_avg_L3  \\\n",
       "0             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1             NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2       82.666667    0.463667   24.666667    0.353667   21.000000    0.755000   \n",
       "3       84.666667    0.453333   25.333333    0.335333   20.666667    0.798000   \n",
       "4       87.000000    0.421667   24.333333    0.307333   19.333333    0.825000   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "14941   92.000000    0.500000   26.666667    0.322000   22.333333    0.809667   \n",
       "14942   91.000000    0.524333   23.000000    0.347667   20.333333    0.806333   \n",
       "14943   91.000000    0.513333   23.333333    0.330333   23.666667    0.734000   \n",
       "14944   92.000000    0.451667   25.666667    0.240000   23.333333    0.731000   \n",
       "14945   92.000000    0.417667   27.000000    0.231667   32.333333    0.726333   \n",
       "\n",
       "       orb_avg_L3  trb_avg_L3  ast_avg_L3  stl_avg_L3  ...  tov_opp_avg_L5  \\\n",
       "0             NaN         NaN         NaN         NaN  ...             NaN   \n",
       "1             NaN         NaN         NaN         NaN  ...             NaN   \n",
       "2        7.333333   41.333333   23.666667    9.666667  ...             NaN   \n",
       "3        8.000000   44.000000   23.666667    9.666667  ...             NaN   \n",
       "4       11.000000   48.000000   23.333333    9.333333  ...            16.6   \n",
       "...           ...         ...         ...         ...  ...             ...   \n",
       "14941   10.000000   51.333333   24.333333    5.333333  ...            13.2   \n",
       "14942    9.000000   47.333333   25.666667    5.333333  ...            12.6   \n",
       "14943    9.000000   44.333333   27.333333    4.666667  ...            11.4   \n",
       "14944   11.000000   40.666667   22.000000    4.000000  ...            12.2   \n",
       "14945   13.000000   46.000000   21.333333    5.333333  ...            12.4   \n",
       "\n",
       "       pf_opp_avg_L5  pts_opp_avg_L5  ts%_opp_avg_L5  efg%_opp_avg_L5  \\\n",
       "0                NaN             NaN             NaN              NaN   \n",
       "1                NaN             NaN             NaN              NaN   \n",
       "2                NaN             NaN             NaN              NaN   \n",
       "3                NaN             NaN             NaN              NaN   \n",
       "4               18.8            97.0          0.4958           0.4580   \n",
       "...              ...             ...             ...              ...   \n",
       "14941           18.6           113.6          0.5522           0.5042   \n",
       "14942           18.0           114.6          0.5464           0.4998   \n",
       "14943           18.0           117.6          0.5584           0.5166   \n",
       "14944           20.0           122.0          0.5910           0.5598   \n",
       "14945           22.6           121.2          0.5866           0.5608   \n",
       "\n",
       "       3par_opp_avg_L5  drb%_opp_avg_L5  trb%_opp_avg_L5  ortg_opp_avg_L5  \\\n",
       "0                  NaN              NaN              NaN              NaN   \n",
       "1                  NaN              NaN              NaN              NaN   \n",
       "2                  NaN              NaN              NaN              NaN   \n",
       "3                  NaN              NaN              NaN              NaN   \n",
       "4               0.3422            79.74            53.34           100.26   \n",
       "...                ...              ...              ...              ...   \n",
       "14941           0.4342            77.84            48.18           109.36   \n",
       "14942           0.4262            77.12            47.10           110.90   \n",
       "14943           0.3882            76.82            48.00           114.30   \n",
       "14944           0.3682            77.02            50.24           118.90   \n",
       "14945           0.3536            77.14            49.38           116.98   \n",
       "\n",
       "       drtg_opp_avg_L5  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4               102.18  \n",
       "...                ...  \n",
       "14941           113.80  \n",
       "14942           114.76  \n",
       "14943           110.18  \n",
       "14944           108.06  \n",
       "14945           111.22  \n",
       "\n",
       "[14946 rows x 84 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2624bacb-823f-44f3-9272-8c6077711942",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, y_train_2, X_test_2, y_test_2 = train_test_split(nba_clean_data,\n",
    "                                                            model_variables,\n",
    "                                                            2022,\n",
    "                                                            None, \n",
    "                                                            True,True,\n",
    "                                                            False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b930b362-d64d-4630-9ec8-8e44b17c0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train_2,X_train],axis=1)\n",
    "test = pd.concat([X_test_2,X_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "932c9a47-d93e-4857-8f93-f824d24111a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5885855747357153, 0.5053516819571865]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.39      0.44      1308\n",
      "           1       0.50      0.62      0.56      1308\n",
      "\n",
      "    accuracy                           0.51      2616\n",
      "   macro avg       0.51      0.51      0.50      2616\n",
      "weighted avg       0.51      0.51      0.50      2616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_classifier = lgb.LGBMClassifier(num_leaves=10, max_depth=2,random_state=0,verbose=-1)\n",
    "\n",
    "lgb_classifier.fit(train,y_train)\n",
    "print([lgb_classifier.score(train,y_train),lgb_classifier.score(test,y_test)])\n",
    "test_pred = lgb_classifier.predict(test)\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655cb6d8-1ad6-480d-9170-9dd495db45bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
